# Supabase Configuration
# Client-side (public)
NEXT_PUBLIC_SUPABASE_URL=           # Your Supabase project URL
NEXT_PUBLIC_SUPABASE_ANON_KEY=      # Your Supabase anon/public key

# Server-side only (private)
SUPABASE_URL=                       # Same as NEXT_PUBLIC_SUPABASE_URL
SUPABASE_KEY=                       # IMPORTANT: Must be the SERVICE ROLE KEY, not anon key

# Vector Database Configuration
VECTOR_DB_PASSWORD=
VECTOR_JWT_SECRET=
NEXT_PUBLIC_VECTOR_SUPABASE_URL=
VECTOR_SUPABASE_URL=
VECTOR_SUPABASE_SERVICE_KEY=
NEXT_PUBLIC_VECTOR_SUPABASE_ANON_KEY=

# Note: We use service role key in API routes because:
# 1. The AI chat needs to read any user's messages
# 2. We need to bypass Row Level Security (RLS)
# 3. This is a backend service, not a frontend application

# Environment
NODE_ENV=                     # development or production
PORT=

# Build Configuration
NEXT_DISABLE_ESLINT=
NEXT_DISABLE_TYPE_CHECKS=

# OpenAI Configuration
OPENAI_API_KEY=

# API Security
TENSAI_KEY=                   # Required for accessing the chat endpoint

# Vercel Configuration
CRON_SECRET=

# Langchain Configuration
LANGSMITH_TRACING=
LANGSMITH_ENDPOINT=
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=

# Development vs Production Notes:
# 1. Use different Supabase projects for dev/prod
# 3. Can use same OpenAI key for both, but separate keys recommended
# 4. Set NODE_ENV appropriately for each environment
# 5. Use different TENSAI_KEY values for dev/prod environments
# 6. DEVELOPMENT_SUPABASE_KEY should be service role key for local instance
# 7. PRODUCTION_SUPABASE_KEY should be service role key for production instance

# Existing Supabase config will be used for vector storage
# No need for separate connection details

# Vector table names
VECTOR_TABLE_NAME=message_embeddings_dev # Use message_embeddings_prod in production

# Add any additional environment-specific variables below 